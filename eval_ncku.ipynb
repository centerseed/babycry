{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sound.SoundReader as reader\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import librosa\n",
    "\n",
    "DATA_ROOT = '/data1/pipeline_dataset/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your model  \n",
    "# e.g. model = load_model()...\n",
    "\n",
    "# Global Setting\n",
    "segment_sec = 6         # length per segment, simulated cubo's audio callback\n",
    "sample_rate = 16000     # Cubo device's defult sample rate\n",
    "cry_limit_sec = 3\n",
    "\n",
    "# detail Setting\n",
    "sensitivity = 20        # Will detect segment with avg_dB\n",
    "segment_cry_threshold = 2  # Threshold for segment cry windows numbers\n",
    "\n",
    "# Global statistic calculation\n",
    "cry_confidences = []\n",
    "cry_total_detections = 0\n",
    "cry_total_hit_in_cry = 0\n",
    "other_total_detections = 0\n",
    "cry_total_hit_in_other = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other: return 0, cry return 1\n",
    "def testSegment(segment):\n",
    "\n",
    "    # if detected cry\n",
    "    return 1\n",
    "\n",
    "    # if no cry\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis = 0)\n",
    "    sigma = np.var(dataset,axis = 0)\n",
    "    return (dataset - mu)/sigma\n",
    "\n",
    "# return: 0 -> other, 1 - >cry\n",
    "def getSegmentLabel(segment, index, meta):\n",
    "    abs_seg = np.abs(segment)\n",
    "    abs_seg += 1\n",
    "    dBs = 20 * np.log10(abs_seg)\n",
    "    dB = np.mean(abs_seg)\n",
    "    if dB < sensitivity:\n",
    "        return 0\n",
    "        \n",
    "    seg_size = len(segment)\n",
    "    seg_start = index * sample_rate * segment_sec\n",
    "    seg_end = seg_start + seg_size\n",
    "    \n",
    "    # get overlapped labeled segment\n",
    "    overlaps = []\n",
    "    for segment in meta['segments']:\n",
    "        start_point = segment['start_ms'] * 16\n",
    "        end_point = segment['end_ms'] * 16\n",
    "        \n",
    "        if seg_end < start_point or seg_start > end_point:\n",
    "            continue\n",
    "        else:\n",
    "            overlaps.append(segment)\n",
    "        \n",
    "    seg_label_overlaps = []\n",
    "    # get overlap ratio\n",
    "    for label in overlaps:\n",
    "        label_start = label['start_ms'] * 16\n",
    "        label_end = label['end_ms'] * 16\n",
    "        \n",
    "        over_start = label_start\n",
    "        if label_start < seg_start:\n",
    "            over_start = seg_start\n",
    "            \n",
    "        over_end = label_end\n",
    "        if label_end > seg_end:\n",
    "            over_end = seg_end\n",
    "            \n",
    "        seg_label_overlaps.append((over_end - over_start, label['class']))\n",
    "        \n",
    "    is_cry = 0\n",
    "    for duration, audio_class in seg_label_overlaps:\n",
    "        if audio_class == 'cry' and duration > cry_limit_sec * sample_rate:\n",
    "            return 1\n",
    "    return 0\n",
    "    \n",
    "def test(audio_path, meta, segment_sec):\n",
    "    print('\\n --------- test {}, labeller: {} ---------'.format(meta['name'], meta['labeller']))\n",
    "    _, sig, sound = reader.readWave(audio_path)\n",
    "        \n",
    "    segments = []\n",
    "    segment_size = sample_rate * segment_sec\n",
    "    \n",
    "    # split audio to segment_sec chunk, no overlap\n",
    "    for i in range(0, len(sig)-segment_size, segment_size):\n",
    "        segments.append(sig[i:i+segment_size])\n",
    "    \n",
    "    # detect per chunk\n",
    "    label_segments = []\n",
    "    resut_segments = []\n",
    "    \n",
    "    for i in range(len(segments)): \n",
    "        segment = segments[i]\n",
    "        \n",
    "        label_is_cry = getSegmentLabel(segment, i, meta)\n",
    "        predict_is_cry = testSegment(segment)\n",
    "        print(\"seg {} label: {} -> predict: {}\".format(i, label_is_cry, predict_is_cry))\n",
    "        \n",
    "        label_segments.append(label_is_cry)\n",
    "        resut_segments.append(predict_is_cry)\n",
    "    return label_segments, resut_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get validation split to test\n",
    "url = 'http://dev.yunyun.cloud:6001/metas/audio?split=val'\n",
    "resp = requests.get(url)\n",
    "metas = resp.json()['metas']\n",
    "print('total val count: {}'.format(len(metas)))\n",
    "\n",
    "correct_count = 0\n",
    "fail_meta = []\n",
    "all_label_is_cry = []\n",
    "all_detect_is_cry = []\n",
    "for meta in metas:\n",
    "    if 'segments' not in meta:\n",
    "        continue\n",
    "        \n",
    "    audio_folder = os.path.join(DATA_ROOT, 'batch_{}'.format(meta['batch_date']))\n",
    "    if not os.path.isdir(audio_folder):\n",
    "        os.makedirs(audio_folder)\n",
    "        \n",
    "    audio_path = os.path.join(audio_folder, meta['name'])\n",
    "    if not os.path.isfile(audio_path):\n",
    "        # download file\n",
    "        url = os.path.join('http://dev.yunyun.cloud:6001/audio', meta['batch_date'], meta['name'])\n",
    "        print('downloading .... {}'.format(url))\n",
    "        r = requests.get(url) \n",
    "        with open(audio_path, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        \n",
    "    labels, results = test(audio_path, meta, segment_sec)\n",
    "            \n",
    "    all_label_is_cry += labels\n",
    "    all_detect_is_cry += results\n",
    "\n",
    "acc = accuracy_score(all_label_is_cry, all_detect_is_cry)\n",
    "print('\\n -------- Report ----------')\n",
    "print(\"Correct rate: {}\".format(acc))\n",
    "print(confusion_matrix(all_label_is_cry, all_detect_is_cry))\n",
    "# print fail case\n",
    "\n",
    "print(' -------- Error Detail -------')\n",
    "for meta in metas:\n",
    "    classes = []\n",
    "    if 'segments' not in meta:\n",
    "        print('{} no label segments'.format(meta['name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
